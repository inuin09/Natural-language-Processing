{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "머신러닝을 이용한 감성분석.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5gS2o4ptu0wao1YEs1zXj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inuin09/Natural-language-Processing/blob/main/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5negdkIxG8JR",
        "outputId": "a74bdf17-1a78-4dcb-c633-1f2cbe3e69cf"
      },
      "source": [
        "#구글 드라이브와 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipbF-xu-HVw4"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk\n",
        "!pip install JPype1==0.7.4\n",
        "!pip install rhinoMorph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aTjznJ6HnJ8",
        "outputId": "b6802eb8-39f6-435c-ca73-71a9a205b4dd"
      },
      "source": [
        "#파일이 있는 곳으로 경로를 변경한다.\n",
        "%cd/content/gdrive/My\\ Drive/pytest/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/pytest\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRK1frTxH6N7",
        "outputId": "dfb30ffc-c19b-4572-d24b-91adc8d8d40b"
      },
      "source": [
        "#형태 분석된 데이터 로딩\n",
        "#데이터 로딩\n",
        "def read_data(filename, encoding='cp949'):  #읽기 함수 정의 , cp949 ??\n",
        "  with open(filename, 'r', encoding=encoding) as f:\n",
        "    data = [line.split('\\t') for line in f.read().splitlines()]  \n",
        "    #txt 파일의 헤더(id document label)는 제외하기\n",
        "    #문장 분리-> 각 문장에서 탭 부분 분리 -> 리스트 생성 ->전체로는 중첩 리스트\n",
        "    data=data[1:]\n",
        "  return data\n",
        "\n",
        "def write_data(data, filename, encoding='cp949'):  #쓰기 함수도 정의 \n",
        "  with open(filename, 'w', encoding=encoding) as f:\n",
        "    f.write(data)\n",
        "\n",
        "data = read_data('ratings_morphed.txt', encoding='cp949')  #전체 파일은 ratings.txt\n",
        "print(len(data))\n",
        "print(len(data[0]))\n",
        "print(data[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "491\n",
            "3\n",
            "['4655635', '폴리스스토리 시리즈 뉴 없다 최고', '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OtkAazAIcwv",
        "outputId": "b7db6c81-5163-4133-cfeb-cba6965237f7"
      },
      "source": [
        "#훈련 데이터와 테스트데이터 분리(자동)\n",
        "data_text = [line[1] for line in data]  #데이터 본문\n",
        "data_senti = [line[2] for line in data]  #데이터 긍부정 부분\n",
        "\n",
        "from sklearn.model_selection import train_test_split #본문과 라벨을 각각 분리\n",
        "train_data_text, test_data_text, train_data_senti, test_data_senti = train_test_split(data_text, data_senti, stratify=data_senti)\n",
        "\n",
        "#Counter 클래스를 이용해 각 분류가 훈련데이터와 테스트데이터에 같은 비율로 들어갔는지 확인해본다.\n",
        "from collections import Counter\n",
        "train_data_senti_freq = Counter(train_data_senti)\n",
        "print('train_data_senti_freq : ', train_data_senti_freq)\n",
        "\n",
        "test_data_senti_freq = Counter(test_data_senti)\n",
        "print('test_data_senti_freq : ',test_data_senti_freq)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data_senti_freq :  Counter({'0': 184, '1': 184})\n",
            "test_data_senti_freq :  Counter({'0': 62, '1': 61})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66hRbqnBJL4W",
        "outputId": "dcab63fe-3306-4d49-e18b-1f291f927675"
      },
      "source": [
        "#훈련 데이터와 테스트데이터 분리(수동)\n",
        "import random\n",
        "random.shuffle(data)  #랜덤하게 섞는다\n",
        "\n",
        "data_70 = int(len(data)*0.7)  #전체 데이터 크기의 70% 숫자를 찾는다\n",
        "train_data = data[:data_70] #앞에서 70% 부분을 잘라 훈련데이터로\n",
        "test_data = data[data_70:]  #그 뒷부분을 테스트 데이터로\n",
        "\n",
        "print('train_data length :', len(train_data)) \n",
        "print('test_data length :', len(test_data))\n",
        "\n",
        "#훈련 데이터 요소 분리\n",
        "train_data_text = [line[1] for line in train_data]  #훈련데이터 본문\n",
        "train_data_senti = [line[2] for line in train_data] #훈련 데이터 긍부정 부분\n",
        "\n",
        "#테스트데이터 요소 분리\n",
        "test_data_text = [line[1] for line in test_data]\n",
        "test_data_senti = [line[2] for line in test_data]  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data length : 343\n",
            "test_data length : 148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QloO40sJ3K7",
        "outputId": "bf2d25c7-1f17-4e68-b4f3-b3dac2588594"
      },
      "source": [
        "#행렬 형태로 변환\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer(min_df=5).fit(train_data_text) #최소 문서 빈도 5이상의 단어만 대상\n",
        "X_train = vect.transform(train_data_text) #행렬 생성\n",
        "print('X_train : \\n', repr(X_train))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train : \n",
            " <343x72 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 943 stored elements in Compressed Sparse Row format>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwKkOkITKgZS",
        "outputId": "c472a036-b774-4ba1-af64-ca4dda7ba3d6"
      },
      "source": [
        "feature_names = vect.get_feature_names()\n",
        "print('특성 개수 : ',len(feature_names))\n",
        "print('처음 20개의 특성 : ',feature_names[:20])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "특성 개수 :  72\n",
            "처음 20개의 특성 :  ['10점', 'ㅋㅋ', 'ㅎㅎ', 'ㅠㅠ', 'ㅡㅡ', '감독', '감동', '같다', '그런', '그렇다', '나오다', '남다', '남자', '내내', '내용', '너무', '다시', '대박', '대하다', '되다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHl8NJZcKvn6",
        "outputId": "3083dcda-0fc7-46c4-c083-700a0c345f2b"
      },
      "source": [
        "#머신러닝 알고리즘 적용\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "y_train = pd.Series(train_data_senti) #리스트 형태를 종속변수가 될 수 있는 1차원 배열(시리즈)로 만든다\n",
        "\n",
        "lr=LogisticRegression(solver='liblinear') #모델 생성\n",
        "lr.fit(X_train, y_train) #모델 훈련"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTpij2g3LIkJ",
        "outputId": "ed5e0da9-5d17-474c-b308-c3656f05d8fa"
      },
      "source": [
        "#테스트 데이터 입력\n",
        "X_test = vect.transform(test_data_text)\n",
        "y_test = pd.Series(test_data_senti)\n",
        "\n",
        "print('테스트 데이터 점수 : ',lr.score(X_test, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 데이터 점수 :  0.7094594594594594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2-Lc9yvLUjm",
        "outputId": "e98db519-9055-4724-e09f-5f2eef61d13f"
      },
      "source": [
        "#1개 데이터 예측\n",
        "#형태소 분석기 시작\n",
        "import rhinoMorph\n",
        "rn = rhinoMorph.startRhino()\n",
        "\n",
        "new_input = '오늘은 정말 재미있는 하루구나!'\n",
        "inputdata=[]\n",
        "morphed_input = rhinoMorph.onlyMorph_list(rn, new_input, pos=['NNG','NNP','VV','VA','XR','IC','MM','MAG','MAJ'])\n",
        "morphed_input = ' '.join(morphed_input)\n",
        "\n",
        "inputdata.append(morphed_input)\n",
        "print('input data :',inputdata)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "filepath:  /usr/local/lib/python3.7/dist-packages\n",
            "classpath:  /usr/local/lib/python3.7/dist-packages/rhinoMorph/lib/rhino.jar\n",
            "JVM is already started~\n",
            "RHINO started!\n",
            "input data : ['오늘 정말 재미있 하루']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTbeQVUsLzo0",
        "outputId": "6f88e183-bd86-4090-d2ef-c98235e5d471"
      },
      "source": [
        "X_input = vect.transform(inputdata)\n",
        "result = lr.predict(X_input)\n",
        "\n",
        "if result == '0':\n",
        "  print('부정적')\n",
        "else:\n",
        "  print('긍정적')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "부정적\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GSTK9AoMH3e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}